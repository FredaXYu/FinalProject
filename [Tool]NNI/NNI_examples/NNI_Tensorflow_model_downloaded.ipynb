{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://nni.readthedocs.io/zh/stable/tutorials/hpo_quickstart_tensorflow/model.html?continueFlag=d47ca216a263dbc2b64a99bca96d70cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Port TensorFlow Quickstart to NNI\n",
    "This is a modified version of `TensorFlow quickstart`_.\n",
    "\n",
    "It can be run directly and will have the exact same result as original version.\n",
    "\n",
    "Furthermore, it enables the ability of auto tuning with an NNI *experiment*, which will be detailed later.\n",
    "\n",
    "It is recommended to run this script directly first to verify the environment.\n",
    "\n",
    "There are 3 key differences from the original version:\n",
    "\n",
    "1. In `Get optimized hyperparameters`_ part, it receives generated hyperparameters.\n",
    "2. In `(Optional) Report intermediate results`_ part, it reports per-epoch accuracy metrics.\n",
    "3. In `Report final result`_ part, it reports final accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nni\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters to be tuned\n",
    "These are the hyperparameters that will be tuned later.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'dense_units': 128,\n",
    "    'activation_type': 'relu',\n",
    "    'dropout_rate': 0.2,\n",
    "    'learning_rate': 0.001,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get optimized hyperparameters\n",
    "If run directly, :func:`nni.get_next_parameter` is a no-op and returns an empty dict.\n",
    "But with an NNI *experiment*, it will receive optimized hyperparameters from tuning algorithm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dense_units': 128, 'activation_type': 'relu', 'dropout_rate': 0.2, 'learning_rate': 0.001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python38\\lib\\site-packages\\nni\\runtime\\platform\\standalone.py:32: RuntimeWarning: \u001b[1m\u001b[31mRunning trial code without runtime. Please check the tutorial if you are new to NNI: \u001b[33mhttps://nni.readthedocs.io/en/stable/tutorials/hpo_quickstart_pytorch/main.html\u001b[0m\n",
      "  warnings.warn(warning_message, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "optimized_params = nni.get_next_parameter()\n",
    "params.update(optimized_params)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 7s 1us/step\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model with hyperparameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(params['dense_units'], activation=params['activation_type']),\n",
    "    tf.keras.layers.Dropout(params['dropout_rate']),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=params['learning_rate'])\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=adam, loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Report intermediate results\n",
    "The callback reports per-epoch accuracy to show learning curve in the web portal.\n",
    "You can also leverage the metrics for early stopping with :doc:`NNI assessors </hpo/assessors>`.\n",
    "\n",
    "This part can be safely skipped and the experiment will work fine.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.LambdaCallback(\n",
    "    on_epoch_end = lambda epoch, logs: nni.report_intermediate_result(logs['accuracy'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evluate the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "[2022-12-10 14:19:08] \u001b[32mIntermediate result: 0.9147666692733765  (Index 0)\u001b[0m\n",
      "1875/1875 - 4s - loss: 0.2924 - accuracy: 0.9148 - 4s/epoch - 2ms/step\n",
      "Epoch 2/5\n",
      "[2022-12-10 14:19:11] \u001b[32mIntermediate result: 0.9584166407585144  (Index 1)\u001b[0m\n",
      "1875/1875 - 3s - loss: 0.1394 - accuracy: 0.9584 - 3s/epoch - 2ms/step\n",
      "Epoch 3/5\n",
      "[2022-12-10 14:19:13] \u001b[32mIntermediate result: 0.9686999917030334  (Index 2)\u001b[0m\n",
      "1875/1875 - 3s - loss: 0.1047 - accuracy: 0.9687 - 3s/epoch - 2ms/step\n",
      "Epoch 4/5\n",
      "[2022-12-10 14:19:16] \u001b[32mIntermediate result: 0.9732333421707153  (Index 3)\u001b[0m\n",
      "1875/1875 - 3s - loss: 0.0868 - accuracy: 0.9732 - 3s/epoch - 2ms/step\n",
      "Epoch 5/5\n",
      "[2022-12-10 14:19:19] \u001b[32mIntermediate result: 0.9767333269119263  (Index 4)\u001b[0m\n",
      "1875/1875 - 3s - loss: 0.0747 - accuracy: 0.9767 - 3s/epoch - 2ms/step\n",
      "313/313 - 0s - loss: 0.0794 - accuracy: 0.9730 - 484ms/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5, verbose=2, callbacks=[callback])\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report final result\n",
    "Report final accuracy to NNI so the tuning algorithm can suggest better hyperparameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-12-10 14:19:23] \u001b[32mFinal result: 0.9729999899864197\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "nni.report_final_result(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
